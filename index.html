<!DOCTYPE html>
<html>

<head>
    <title>Brendan's PhD Thesis</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.1.0/reveal.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.1.0/theme/black.min.css">
    <link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
    <div class="reveal">
        <div class="slides">
            <section>
                <section>
                    <h2>Human Digitization</h2>
                </section>

                <section>
                    <ul>
                        <li>A number of tasks relate to human digitization</li>
                        <li>I mention a few of them below</li>
                    </ul>
                </section>

                <section>
                    <h3>Facial Reenactment</h3>
                </section>

                <section>
                    <ul>
                        <li>Facial reenacment involves learning the shape and appearance of a subject's face</li>
                        <li>We can then render the subject in novel poses and expressions using the learned representation</li>
                    </ul>
                </section>

                <section>
                    <ul>
                        <li>As an example, "NeRF for 4D Facial Avatars" makes use of a 3D morphable model (3DMM) to extend neural radiance fields (NeRF)</li>
                        <li>Vanilla NeRF conditions on position and view direction to predict coefficients for volumetric rendering</li>
                        <li>"NeRF for 4D Facial Avatars" extends NeRF to also condition on pose and expression from a 3DMM</li>
                        <li>After training, the model can render the subject in new facial poses and expressions</li>
                    </ul>
                </section>

                <section>
                    <h4>NeRF for 4D Facial Avatars</h4>
                    <video autoplay loop controls muted src="https://gafniguy.github.io/4D-Facial-Avatars/vid.mp4">
                    </video>
                    <footer>
                        Guy Gafni, Justus Thies, Michael Zollhöfer, and Matthias Nießner.
                        "NerFACE: Dynamic Neural Radiance Fields for Monocular 4D
                        Facial Avatar Reconstruction,"
                        <em>arXiv preprint arXiv:2012.03065</em>, 2020.
                    </footer>
                </section>

                <section>
                    <h3>Person and Scene Reconstruction</h3>
                </section>

                <section>
                    <ul>
                        <li>In 3D reconstruction we want to capture a 3D scene in high fidelity</li>
                        <li>Capturing a 3D scene requires multiple views</li>
                        <li>Foreground motion makes capturing scenes with people more difficult</li>
                    </ul>
                </section>

                <section>
                    <ul>
                        <li>Nerfies extend NeRF to handle scenes with mild deformations</li>
                        <li>They achieve this by introduction a deformation field that deforms input coordinates to a canonical NeRF</li>
                        <li>The resulting model can produce 3D reconstructions of humans from a selfie video, dubbed "Nerfies"</li>
                    </ul>
                </section>

                <section>
                    <h4>NeRFies</h4>
                    <div class="container">
                        <div>
                            <video autoplay controls muted loop>
                                <source src="https://storage.googleapis.com/nerfies-public/videos/steve.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div>
                            <video autoplay controls muted loop>
                                <source src="https://storage.googleapis.com/nerfies-public/videos/chair-tp.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div>
                            <video autoplay controls muted loop>
                                <source src="https://storage.googleapis.com/nerfies-public/videos/shiba.mp4" type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <footer>
                        Keunhong Park, Utkarsh Sinha, Jonathan T. Barron,
                        Sofien Bouaziz, Dan B Goldman, Steven M. Seitz, and
                        Ricardo Martin-Brualla.
                        "Deformable Neural Radiance Fields,"
                        <em>arXiv preprint arXiv:2011.12948</em>, 2020.
                    </footer>
                </section>

                <section>
                    <h3>3D Statistical Model Acquisition</h3>
                </section>

                <section>
                    <ul>
                        <li>3D morphable models (3DMMs) are a 3D generative model for a known shape, e.g., for faces</li>
                        <li>3DMM creation proceeds by first collecting a dataset of 3D scans</li>
                        <li>We then align and register the 3D scans</li>
                        <li>By assuming that the scans lie on a linear subspace, we form a 3DMM by fitting linear shape and expression bases to the aligned scans</li>
                    </ul>
                </section>

                <section>
                    <h4>FLAME</h4>
                    <img data-src="https://flame.is.tue.mpg.de/uploads/ckeditor/pictures/195/content_FLAME_web_viewer.gif" alt="FLAME 3DMM GIF">
                    <footer>
                        Tianye Li, Timo Bolkart, Michael. J. Black, Hao Li, and Javier Romero.
                        "Learning a model of facial shape and expression from 4D scans,"
                        <em>SIGGRAPH Asia</em>, 2017.
                    </footer>
                </section>
            </section>

            <section>
                <section>
                    <h2>Problem</h2>
                    <hr>
                    <h2>Slow Deployment</h2>
                </section>
                <section>
                    <h3>Potential Solution</h3>
                    <hr>
                    <h3>Speedup via Specialization</h3>
                </section>
            </section>

            <section>
                <section>
                    <h2>Problem</h2>
                    <hr>
                    <h2>Data Collection for Niche Tasks</h2>
                </section>
                <section>
                    <h3>Potential Solution</h3>
                    <hr>
                    <h3>Specialization from Generic models</h3>
                </section>
            </section>
        </div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.1.0/reveal.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.1.0/plugin/notes/notes.min.js"></script>
    <script>
        Reveal.initialize({
            plugins: [RevealNotes]
        });
    </script>
</body>

</html>
